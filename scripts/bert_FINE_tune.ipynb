{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>claude_sent</th>\n",
       "      <th>gpt_sent</th>\n",
       "      <th>gpt_sent_2</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nostalgic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive Emotions</td>\n",
       "      <td>Positive Sentiments</td>\n",
       "      <td>\\nThere were bells on a hill\\nBut I never hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intimate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calm and Peaceful</td>\n",
       "      <td>\\nAnd I'm standing on a platform\\nNow I'm star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bittersweet</td>\n",
       "      <td>Pensive/Emotional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complex and Mysterious</td>\n",
       "      <td>\\nThey're gonna send us to prison for jerks\\nF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wistful</td>\n",
       "      <td>Pensive/Emotional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complex and Mysterious</td>\n",
       "      <td>Nothing is ever as good as it was\\nAnd what's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exciting</td>\n",
       "      <td>Positive/Uplifting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Energetic and Exciting</td>\n",
       "      <td>You become pretty when you draw near love\\nLet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label         claude_sent           gpt_sent              gpt_sent_2  \\\n",
       "0    nostalgic                 NaN  Positive Emotions     Positive Sentiments   \n",
       "1     intimate                 NaN                NaN       Calm and Peaceful   \n",
       "2  bittersweet   Pensive/Emotional                NaN  Complex and Mysterious   \n",
       "3      wistful   Pensive/Emotional                NaN  Complex and Mysterious   \n",
       "4     exciting  Positive/Uplifting                NaN  Energetic and Exciting   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \\nThere were bells on a hill\\nBut I never hear...  \n",
       "1  \\nAnd I'm standing on a platform\\nNow I'm star...  \n",
       "2  \\nThey're gonna send us to prison for jerks\\nF...  \n",
       "3  Nothing is ever as good as it was\\nAnd what's ...  \n",
       "4  You become pretty when you draw near love\\nLet...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/lyrics_sentiments.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_lyrics(lyrics):\n",
    "    return tokenizer(lyrics, padding='max_length', truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def model_generation(df, label):\n",
    "    # select columns named lyrics and label\n",
    "    df = df[['lyrics', label]].copy()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    label_map = [(i, label) for i, label in enumerate(df[label].unique())]\n",
    "    df[label] = df[label].map({label: i for i, label in label_map})\n",
    "    \n",
    "    df['lyrics'] = df['lyrics'].str.replace('\\n', ' ')\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    train_encodings = tokenizer(list(train_df['lyrics']), padding=True, truncation=True)\n",
    "    val_encodings = tokenizer(list(val_df['lyrics']), padding=True, truncation=True)\n",
    "    \n",
    "    class LyricsDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = LyricsDataset(train_encodings, train_df[label].tolist())\n",
    "    val_dataset = LyricsDataset(val_encodings, val_df[label].tolist())\n",
    "    \n",
    "    accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        logits, labels = p\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    n_labels = len(df[label].unique())\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=n_labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    results = trainer.evaluate()\n",
    "    \n",
    "    # save the model\n",
    "    \n",
    "    model_name = f\"{label}_model\"\n",
    "    model.save_pretrained(model_name)\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammillington/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c5e7ac31544bff8192e2681e54f571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6642, 'grad_norm': 6.653538703918457, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}\n",
      "{'loss': 4.6606, 'grad_norm': 6.345301151275635, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.13}\n",
      "{'loss': 4.6823, 'grad_norm': 7.635947227478027, 'learning_rate': 3e-06, 'epoch': 0.19}\n",
      "{'loss': 4.6315, 'grad_norm': 5.033979892730713, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 4.6333, 'grad_norm': 5.48937463760376, 'learning_rate': 5e-06, 'epoch': 0.32}\n",
      "{'loss': 4.6255, 'grad_norm': 7.177362442016602, 'learning_rate': 6e-06, 'epoch': 0.38}\n",
      "{'loss': 4.6127, 'grad_norm': 5.38101053237915, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.44}\n",
      "{'loss': 4.6526, 'grad_norm': 7.737237930297852, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 4.6272, 'grad_norm': 5.230264663696289, 'learning_rate': 9e-06, 'epoch': 0.57}\n",
      "{'loss': 4.6322, 'grad_norm': 6.384013652801514, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 4.6514, 'grad_norm': 6.311906337738037, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.7}\n",
      "{'loss': 4.6093, 'grad_norm': 4.489814758300781, 'learning_rate': 1.2e-05, 'epoch': 0.76}\n",
      "{'loss': 4.6163, 'grad_norm': 3.500755548477173, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.82}\n",
      "{'loss': 4.5794, 'grad_norm': 4.849625587463379, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.89}\n",
      "{'loss': 4.5983, 'grad_norm': 11.489747047424316, 'learning_rate': 1.5e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a04e2071c74ea78bcf4b0d50d231e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.565482139587402, 'eval_accuracy': 0.02694136291600634, 'eval_runtime': 13.7725, 'eval_samples_per_second': 45.816, 'eval_steps_per_second': 2.904, 'epoch': 1.0}\n",
      "{'loss': 4.588, 'grad_norm': 5.406882286071777, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.01}\n",
      "{'loss': 4.5361, 'grad_norm': 5.33447265625, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.08}\n",
      "{'loss': 4.5162, 'grad_norm': 5.928139686584473, 'learning_rate': 1.8e-05, 'epoch': 1.14}\n",
      "{'loss': 4.519, 'grad_norm': 5.009749412536621, 'learning_rate': 1.9e-05, 'epoch': 1.2}\n",
      "{'loss': 4.5183, 'grad_norm': 4.946057319641113, 'learning_rate': 2e-05, 'epoch': 1.27}\n",
      "{'loss': 4.5434, 'grad_norm': 5.765203952789307, 'learning_rate': 2.1e-05, 'epoch': 1.33}\n",
      "{'loss': 4.5197, 'grad_norm': 6.280948162078857, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.39}\n",
      "{'loss': 4.5215, 'grad_norm': 6.412256240844727, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.46}\n",
      "{'loss': 4.5538, 'grad_norm': 5.221756458282471, 'learning_rate': 2.4e-05, 'epoch': 1.52}\n",
      "{'loss': 4.5744, 'grad_norm': 5.8327789306640625, 'learning_rate': 2.5e-05, 'epoch': 1.58}\n",
      "{'loss': 4.5289, 'grad_norm': 6.1264448165893555, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.65}\n",
      "{'loss': 4.5042, 'grad_norm': 5.5491719245910645, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.71}\n",
      "{'loss': 4.6097, 'grad_norm': 6.670449256896973, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.77}\n",
      "{'loss': 4.57, 'grad_norm': 4.927413463592529, 'learning_rate': 2.9e-05, 'epoch': 1.84}\n",
      "{'loss': 4.6147, 'grad_norm': 6.26853084564209, 'learning_rate': 3e-05, 'epoch': 1.9}\n",
      "{'loss': 4.6104, 'grad_norm': 5.621958255767822, 'learning_rate': 3.1e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a009301c74894bab818241c19c6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.582465648651123, 'eval_accuracy': 0.011093502377179081, 'eval_runtime': 13.9768, 'eval_samples_per_second': 45.146, 'eval_steps_per_second': 2.862, 'epoch': 2.0}\n",
      "{'loss': 4.6111, 'grad_norm': 4.635292053222656, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.03}\n",
      "{'loss': 4.5209, 'grad_norm': 4.951947212219238, 'learning_rate': 3.3e-05, 'epoch': 2.09}\n",
      "{'loss': 4.4624, 'grad_norm': 5.682195663452148, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.15}\n",
      "{'loss': 4.5617, 'grad_norm': 5.325401306152344, 'learning_rate': 3.5e-05, 'epoch': 2.22}\n",
      "{'loss': 4.4538, 'grad_norm': 7.407135009765625, 'learning_rate': 3.6e-05, 'epoch': 2.28}\n",
      "{'loss': 4.4972, 'grad_norm': 8.817619323730469, 'learning_rate': 3.7e-05, 'epoch': 2.34}\n",
      "{'loss': 4.4829, 'grad_norm': 6.228271007537842, 'learning_rate': 3.8e-05, 'epoch': 2.41}\n",
      "{'loss': 4.4623, 'grad_norm': 6.047979354858398, 'learning_rate': 3.9000000000000006e-05, 'epoch': 2.47}\n",
      "{'loss': 4.3696, 'grad_norm': 5.072359561920166, 'learning_rate': 4e-05, 'epoch': 2.53}\n",
      "{'loss': 4.4062, 'grad_norm': 6.372434616088867, 'learning_rate': 4.1e-05, 'epoch': 2.59}\n",
      "{'loss': 4.4642, 'grad_norm': 5.739339828491211, 'learning_rate': 4.2e-05, 'epoch': 2.66}\n",
      "{'loss': 4.4648, 'grad_norm': 5.584926128387451, 'learning_rate': 4.3e-05, 'epoch': 2.72}\n",
      "{'loss': 4.5065, 'grad_norm': 5.348135948181152, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.78}\n",
      "{'loss': 4.518, 'grad_norm': 8.405653953552246, 'learning_rate': 4.5e-05, 'epoch': 2.85}\n",
      "{'loss': 4.4706, 'grad_norm': 7.924073696136475, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.91}\n",
      "{'loss': 4.4021, 'grad_norm': 6.107155799865723, 'learning_rate': 4.7e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384d7da6f8fb432daef0e2641e3f1515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.474768161773682, 'eval_accuracy': 0.03645007923930269, 'eval_runtime': 14.2589, 'eval_samples_per_second': 44.253, 'eval_steps_per_second': 2.805, 'epoch': 3.0}\n",
      "{'train_runtime': 577.0927, 'train_samples_per_second': 13.116, 'train_steps_per_second': 0.821, 'train_loss': 4.5516098601908626, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0df7d8f96f4af5ae3bbf99fc04f97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 'label'\n",
    "\n",
    "seeds_accuracy = model_generation(df, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammillington/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da674da695ea4720a0b370ad4244bfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5297, 'grad_norm': 7.556830883026123, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.13}\n",
      "{'loss': 1.5686, 'grad_norm': 4.945971488952637, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.25}\n",
      "{'loss': 1.5724, 'grad_norm': 4.56644868850708, 'learning_rate': 3e-06, 'epoch': 0.38}\n",
      "{'loss': 1.5082, 'grad_norm': 5.777831077575684, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 1.599, 'grad_norm': 7.73043966293335, 'learning_rate': 5e-06, 'epoch': 0.63}\n",
      "{'loss': 1.5577, 'grad_norm': 4.820255756378174, 'learning_rate': 6e-06, 'epoch': 0.76}\n",
      "{'loss': 1.569, 'grad_norm': 3.754528284072876, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e37736d01ec4581ba22a7381efaa13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5769931077957153, 'eval_accuracy': 0.2911392405063291, 'eval_runtime': 9.4583, 'eval_samples_per_second': 33.41, 'eval_steps_per_second': 2.115, 'epoch': 1.0}\n",
      "{'loss': 1.571, 'grad_norm': 4.588228702545166, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.01}\n",
      "{'loss': 1.531, 'grad_norm': 5.3220696449279785, 'learning_rate': 9e-06, 'epoch': 1.14}\n",
      "{'loss': 1.5192, 'grad_norm': 4.875345706939697, 'learning_rate': 1e-05, 'epoch': 1.27}\n",
      "{'loss': 1.5829, 'grad_norm': 11.830602645874023, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.39}\n",
      "{'loss': 1.5124, 'grad_norm': 4.759320259094238, 'learning_rate': 1.2e-05, 'epoch': 1.52}\n",
      "{'loss': 1.5328, 'grad_norm': 7.466587066650391, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.65}\n",
      "{'loss': 1.5546, 'grad_norm': 4.177201271057129, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.77}\n",
      "{'loss': 1.5724, 'grad_norm': 4.968449115753174, 'learning_rate': 1.5e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3425aa02d84a4cef9f59a9c84c490d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5674939155578613, 'eval_accuracy': 0.3069620253164557, 'eval_runtime': 7.09, 'eval_samples_per_second': 44.57, 'eval_steps_per_second': 2.821, 'epoch': 2.0}\n",
      "{'loss': 1.4899, 'grad_norm': 5.359111309051514, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.03}\n",
      "{'loss': 1.4849, 'grad_norm': 5.272211074829102, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.15}\n",
      "{'loss': 1.4512, 'grad_norm': 6.004427433013916, 'learning_rate': 1.8e-05, 'epoch': 2.28}\n",
      "{'loss': 1.4284, 'grad_norm': 8.520371437072754, 'learning_rate': 1.9e-05, 'epoch': 2.41}\n",
      "{'loss': 1.4448, 'grad_norm': 14.146289825439453, 'learning_rate': 2e-05, 'epoch': 2.53}\n",
      "{'loss': 1.4504, 'grad_norm': 8.017539024353027, 'learning_rate': 2.1e-05, 'epoch': 2.66}\n",
      "{'loss': 1.4673, 'grad_norm': 17.838943481445312, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.78}\n",
      "{'loss': 1.5021, 'grad_norm': 6.6927642822265625, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e09b2c9c6043b3b920ab323c883583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5809441804885864, 'eval_accuracy': 0.2879746835443038, 'eval_runtime': 6.5107, 'eval_samples_per_second': 48.535, 'eval_steps_per_second': 3.072, 'epoch': 3.0}\n",
      "{'train_runtime': 352.5797, 'train_samples_per_second': 10.738, 'train_steps_per_second': 0.672, 'train_loss': 1.5231522306611267, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c274296ec13c4e29aebee5b55ff8d416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 'claude_sent'\n",
    "\n",
    "claude_accuracy = model_generation(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammillington/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b2a8d7f27c48638b85537f47404850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6184, 'grad_norm': 6.676315784454346, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.13}\n",
      "{'loss': 1.6198, 'grad_norm': 6.715231895446777, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.26}\n",
      "{'loss': 1.6605, 'grad_norm': 8.723931312561035, 'learning_rate': 3e-06, 'epoch': 0.38}\n",
      "{'loss': 1.638, 'grad_norm': 6.926366329193115, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 1.5736, 'grad_norm': 5.122390270233154, 'learning_rate': 5e-06, 'epoch': 0.64}\n",
      "{'loss': 1.5799, 'grad_norm': 5.905638217926025, 'learning_rate': 6e-06, 'epoch': 0.77}\n",
      "{'loss': 1.5926, 'grad_norm': 6.000736236572266, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e927fc04f64216899fd6d4b0e4db47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.53018057346344, 'eval_accuracy': 0.32051282051282054, 'eval_runtime': 4.7432, 'eval_samples_per_second': 65.778, 'eval_steps_per_second': 4.217, 'epoch': 1.0}\n",
      "{'loss': 1.5503, 'grad_norm': 8.733366012573242, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.03}\n",
      "{'loss': 1.5717, 'grad_norm': 5.31638765335083, 'learning_rate': 9e-06, 'epoch': 1.15}\n",
      "{'loss': 1.4956, 'grad_norm': 8.342581748962402, 'learning_rate': 1e-05, 'epoch': 1.28}\n",
      "{'loss': 1.5389, 'grad_norm': 4.520341873168945, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.41}\n",
      "{'loss': 1.575, 'grad_norm': 3.8851308822631836, 'learning_rate': 1.2e-05, 'epoch': 1.54}\n",
      "{'loss': 1.4926, 'grad_norm': 7.710490703582764, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.67}\n",
      "{'loss': 1.5546, 'grad_norm': 6.679062843322754, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.79}\n",
      "{'loss': 1.5948, 'grad_norm': 5.930582046508789, 'learning_rate': 1.5e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4003a53646184d0581e91acc3f11c659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5252299308776855, 'eval_accuracy': 0.32051282051282054, 'eval_runtime': 5.1621, 'eval_samples_per_second': 60.441, 'eval_steps_per_second': 3.874, 'epoch': 2.0}\n",
      "{'loss': 1.5299, 'grad_norm': 9.799586296081543, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.05}\n",
      "{'loss': 1.5257, 'grad_norm': 3.128535747528076, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.18}\n",
      "{'loss': 1.4869, 'grad_norm': 4.127585411071777, 'learning_rate': 1.8e-05, 'epoch': 2.31}\n",
      "{'loss': 1.4779, 'grad_norm': 7.798474311828613, 'learning_rate': 1.9e-05, 'epoch': 2.44}\n",
      "{'loss': 1.6007, 'grad_norm': 5.479226112365723, 'learning_rate': 2e-05, 'epoch': 2.56}\n",
      "{'loss': 1.5142, 'grad_norm': 3.8015360832214355, 'learning_rate': 2.1e-05, 'epoch': 2.69}\n",
      "{'loss': 1.501, 'grad_norm': 6.2907023429870605, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.82}\n",
      "{'loss': 1.488, 'grad_norm': 5.315500736236572, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1006ff4d984490a4a9ce36c5212991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4895938634872437, 'eval_accuracy': 0.34935897435897434, 'eval_runtime': 6.5098, 'eval_samples_per_second': 47.928, 'eval_steps_per_second': 3.072, 'epoch': 3.0}\n",
      "{'train_runtime': 243.9541, 'train_samples_per_second': 15.31, 'train_steps_per_second': 0.959, 'train_loss': 1.5530352144159822, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86da1909e86445ff941c029ebf7e3567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 'gpt_sent'\n",
    "\n",
    "gpt_accuracy = model_generation(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammillington/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78779efba214b07bbf7e9350db0b56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6149, 'grad_norm': 5.005006790161133, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}\n",
      "{'loss': 1.6571, 'grad_norm': 8.172957420349121, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.13}\n",
      "{'loss': 1.6544, 'grad_norm': 6.283621788024902, 'learning_rate': 3e-06, 'epoch': 0.19}\n",
      "{'loss': 1.5723, 'grad_norm': 11.587963104248047, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 1.5758, 'grad_norm': 7.33373498916626, 'learning_rate': 5e-06, 'epoch': 0.32}\n",
      "{'loss': 1.5732, 'grad_norm': 6.910074710845947, 'learning_rate': 6e-06, 'epoch': 0.38}\n",
      "{'loss': 1.6167, 'grad_norm': 9.072874069213867, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.45}\n",
      "{'loss': 1.5846, 'grad_norm': 4.08292818069458, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 1.5722, 'grad_norm': 5.138309955596924, 'learning_rate': 9e-06, 'epoch': 0.57}\n",
      "{'loss': 1.5531, 'grad_norm': 7.2225751876831055, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5711, 'grad_norm': 4.513034343719482, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5563, 'grad_norm': 5.172163009643555, 'learning_rate': 1.2e-05, 'epoch': 0.76}\n",
      "{'loss': 1.6158, 'grad_norm': 6.9940409660339355, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.83}\n",
      "{'loss': 1.5951, 'grad_norm': 3.181535005569458, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.89}\n",
      "{'loss': 1.5725, 'grad_norm': 4.926751613616943, 'learning_rate': 1.5e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79084f9b6621411ab6118f0f38d5f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5765527486801147, 'eval_accuracy': 0.28594249201277955, 'eval_runtime': 13.4474, 'eval_samples_per_second': 46.552, 'eval_steps_per_second': 2.975, 'epoch': 1.0}\n",
      "{'loss': 1.5871, 'grad_norm': 5.493659019470215, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.02}\n",
      "{'loss': 1.578, 'grad_norm': 5.316946983337402, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.08}\n",
      "{'loss': 1.5573, 'grad_norm': 4.193392276763916, 'learning_rate': 1.8e-05, 'epoch': 1.15}\n",
      "{'loss': 1.5182, 'grad_norm': 4.210460662841797, 'learning_rate': 1.9e-05, 'epoch': 1.21}\n",
      "{'loss': 1.5219, 'grad_norm': 3.9745044708251953, 'learning_rate': 2e-05, 'epoch': 1.27}\n",
      "{'loss': 1.5391, 'grad_norm': 7.695709705352783, 'learning_rate': 2.1e-05, 'epoch': 1.34}\n",
      "{'loss': 1.5133, 'grad_norm': 6.257134437561035, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.4}\n",
      "{'loss': 1.5162, 'grad_norm': 6.2271199226379395, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.46}\n",
      "{'loss': 1.5289, 'grad_norm': 5.927811622619629, 'learning_rate': 2.4e-05, 'epoch': 1.53}\n",
      "{'loss': 1.5962, 'grad_norm': 8.953492164611816, 'learning_rate': 2.5e-05, 'epoch': 1.59}\n",
      "{'loss': 1.6305, 'grad_norm': 4.887137413024902, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.66}\n",
      "{'loss': 1.5825, 'grad_norm': 6.005653381347656, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.72}\n",
      "{'loss': 1.6063, 'grad_norm': 5.897922039031982, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.78}\n",
      "{'loss': 1.6029, 'grad_norm': 5.171060085296631, 'learning_rate': 2.9e-05, 'epoch': 1.85}\n",
      "{'loss': 1.5913, 'grad_norm': 2.7509894371032715, 'learning_rate': 3e-05, 'epoch': 1.91}\n",
      "{'loss': 1.5229, 'grad_norm': 5.160025596618652, 'learning_rate': 3.1e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a187b9dfb9343da9ec9c4c3ad207e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5792171955108643, 'eval_accuracy': 0.28753993610223644, 'eval_runtime': 12.0243, 'eval_samples_per_second': 52.061, 'eval_steps_per_second': 3.327, 'epoch': 2.0}\n",
      "{'loss': 1.5838, 'grad_norm': 3.844600200653076, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.04}\n",
      "{'loss': 1.5271, 'grad_norm': 5.161525249481201, 'learning_rate': 3.3e-05, 'epoch': 2.1}\n",
      "{'loss': 1.5036, 'grad_norm': 4.142090797424316, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.17}\n",
      "{'loss': 1.5691, 'grad_norm': 7.037516117095947, 'learning_rate': 3.5e-05, 'epoch': 2.23}\n",
      "{'loss': 1.5179, 'grad_norm': 4.483217239379883, 'learning_rate': 3.6e-05, 'epoch': 2.29}\n",
      "{'loss': 1.4607, 'grad_norm': 4.090171813964844, 'learning_rate': 3.7e-05, 'epoch': 2.36}\n",
      "{'loss': 1.504, 'grad_norm': 6.272985458374023, 'learning_rate': 3.8e-05, 'epoch': 2.42}\n",
      "{'loss': 1.5088, 'grad_norm': 5.160446643829346, 'learning_rate': 3.9000000000000006e-05, 'epoch': 2.48}\n",
      "{'loss': 1.5074, 'grad_norm': 5.832645893096924, 'learning_rate': 4e-05, 'epoch': 2.55}\n",
      "{'loss': 1.5341, 'grad_norm': 10.705926895141602, 'learning_rate': 4.1e-05, 'epoch': 2.61}\n",
      "{'loss': 1.5324, 'grad_norm': 5.6329145431518555, 'learning_rate': 4.2e-05, 'epoch': 2.68}\n",
      "{'loss': 1.535, 'grad_norm': 6.935638427734375, 'learning_rate': 4.3e-05, 'epoch': 2.74}\n",
      "{'loss': 1.5294, 'grad_norm': 4.05562686920166, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.8}\n",
      "{'loss': 1.518, 'grad_norm': 4.306895732879639, 'learning_rate': 4.5e-05, 'epoch': 2.87}\n",
      "{'loss': 1.5124, 'grad_norm': 3.476840019226074, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.93}\n",
      "{'loss': 1.5617, 'grad_norm': 4.016234874725342, 'learning_rate': 4.7e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5475a8ea171f461786e2830594675089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.516116976737976, 'eval_accuracy': 0.3242811501597444, 'eval_runtime': 15.4709, 'eval_samples_per_second': 40.463, 'eval_steps_per_second': 2.586, 'epoch': 3.0}\n",
      "{'train_runtime': 658.6679, 'train_samples_per_second': 11.396, 'train_steps_per_second': 0.715, 'train_loss': 1.5587587186991536, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f025a8fb06456d932cfb8a7fd9ff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 'gpt_sent_2'\n",
    "\n",
    "gpt_2_accuracy = model_generation(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from the Individual Labels Model                      Loss: 4.47 | Accuracy: 3.65%\n",
      "Results from the Categories assigned by Claude Model:         Loss: 1.58 | Accuracy: 28.80%\n",
      "Results from the first categories assigned by GPT Model:      Loss: 1.49 | Accuracy: 34.94%\n",
      "Results from the second categories assigned by GPT Model:     Loss: 1.52 | Accuracy: 32.43%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results from the Individual Labels Model                      Loss: {seeds_accuracy['eval_loss']:.2f} | Accuracy: {100*seeds_accuracy['eval_accuracy']:.2f}%\")\n",
    "print(f\"Results from the Categories assigned by Claude Model:         Loss: {claude_accuracy['eval_loss']:.2f} | Accuracy: {100*claude_accuracy['eval_accuracy']:.2f}%\")\n",
    "print(f\"Results from the first categories assigned by GPT Model:      Loss: {gpt_accuracy['eval_loss']:.2f} | Accuracy: {100*gpt_accuracy['eval_accuracy']:.2f}%\")\n",
    "print(f\"Results from the second categories assigned by GPT Model:     Loss: {gpt_2_accuracy['eval_loss']:.2f} | Accuracy: {100*gpt_2_accuracy['eval_accuracy']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
